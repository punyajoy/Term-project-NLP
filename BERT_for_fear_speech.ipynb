{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0427 08:10:52.682808 139727928391488 file_utils.py:38] PyTorch version 1.1.0 available.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from bert_codes.feature_generation import combine_features,return_dataloader,return_cnngru_dataloader\n",
    "from bert_codes.data_extractor import data_collector\n",
    "from bert_codes.own_bert_models import *\n",
    "from bert_codes.utils import *\n",
    "from transformers import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from sklearn.metrics import accuracy_score,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "\t# Tell PyTorch to use the GPU.    \n",
    "\tdevice = torch.device(\"cuda\")\n",
    "\tprint('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\tprint('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "\tprint('No GPU available, using the CPU instead.')\n",
    "\tdevice = torch.device(\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eval_phase(params,test_dataloader,which_files='test',model=None):\n",
    "    model.eval()\n",
    "    print(\"Running eval on \",which_files,\"...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    # Tracking variables \n",
    "    eval_loss=0.0\n",
    "    nb_eval_steps=0\n",
    "    true_labels=[]\n",
    "    pred_labels=[]\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        logits = outputs[0]\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Accumulate the total accuracy.\n",
    "        pred_labels+=list(np.argmax(logits, axis=1).flatten())\n",
    "        true_labels+=list(label_ids.flatten())\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    testf1=f1_score(true_labels, pred_labels, average='macro')\n",
    "    testacc=accuracy_score(true_labels,pred_labels)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\" Accuracy: {0:.2f}\".format(testacc))\n",
    "    print(\" Fscore: {0:.2f}\".format(testf1))\n",
    "    print(\" Test took: {:}\".format(format_time(time.time() - t0)))\n",
    "    return testf1,testacc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_bert(params):\n",
    "    total_data=pd.read_csv('Total_data_annotated.csv')\n",
    "    all_sentences = total_data.text\n",
    "    all_labels=total_data.label\n",
    "    print('Loading BERT tokenizer...')\n",
    "    tokenizer = BertTokenizer.from_pretrained(params['path_files'], do_lower_case=False)\n",
    "    input_total_ids,att_masks_total=combine_features(all_sentences,tokenizer,params['max_length'],\n",
    "                                                     take_pair=False,take_target=False)\n",
    "    \n",
    "    ###optimizer\n",
    "    \n",
    "        \n",
    "    skf=StratifiedKFold(n_splits=10, random_state=params['random_seed'], shuffle=False)\n",
    "    for train_index, test_index in skf.split(input_total_ids, all_labels):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        input_train_ids,att_masks_train,labels_train=input_total_ids[train_index],att_masks_total[train_index],all_labels[train_index]\n",
    "        input_val_ids,att_masks_val,labels_val=input_total_ids[test_index],att_masks_total[test_index],all_labels[test_index]\n",
    "        \n",
    "        model=select_model(params['what_bert'],params['path_files'])\n",
    "        model.cuda()\n",
    "        optimizer = AdamW(model.parameters(),\n",
    "                      lr = params['learning_rate'], # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                      eps = params['epsilon'] # args.adam_epsilon  - default is 1e-8.\n",
    "                    )\n",
    "\n",
    "        \n",
    "        train_dataloader = return_dataloader(input_train_ids,labels_train,att_masks_train,batch_size=params['batch_size'],is_train=params['is_train'])\n",
    "        validation_dataloader=return_dataloader(input_val_ids,labels_val,att_masks_val,batch_size=params['batch_size'],is_train=False)\n",
    "        total_steps = len(train_dataloader) * params['epochs']\n",
    "\n",
    "        # Create the learning rate scheduler.\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                    num_warmup_steps = int(total_steps/10), # Default value in run_glue.py\n",
    "                                                    num_training_steps = total_steps)\n",
    "\n",
    "        # Set the seed value all over the place to make this reproducible.\n",
    "        fix_the_random(seed_val = params['random_seed'])\n",
    "        # Store the averaggit pull origin master --allow-unrelated-historiese loss after each epoch so we can plot them.\n",
    "        loss_values = []\n",
    "\n",
    "        bert_model = params['path_files']\n",
    "        best_val_fscore=0\n",
    "        best_test_fscore=0\n",
    "        for epoch_i in range(0, params['epochs']):\n",
    "            print(\"\")\n",
    "            print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, params['epochs']))\n",
    "            print('Training...')\n",
    "\n",
    "            # Measure how long the training epoch takes.\n",
    "            t0 = time.time()\n",
    "\n",
    "            # Reset the total loss for this epoch.\n",
    "            total_loss = 0\n",
    "            model.train()\n",
    "\n",
    "            # For each batch of training data...\n",
    "            for step, batch in tqdm(enumerate(train_dataloader)):\n",
    "\n",
    "                # Progress update every 40 batches.\n",
    "                if step % 40 == 0 and not step == 0:\n",
    "                    # Calculate elapsed time in minutes.\n",
    "                    elapsed = format_time(time.time() - t0)\n",
    "                # `batch` contains three pytorch tensors:\n",
    "                #   [0]: input ids \n",
    "                #   [1]: attention masks\n",
    "                #   [2]: labels \n",
    "                b_input_ids = batch[0].to(device)\n",
    "                b_input_mask = batch[1].to(device)\n",
    "                b_labels = batch[2].to(device)\n",
    "                # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "                model.zero_grad()        \n",
    "\n",
    "                outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask, \n",
    "                            labels=b_labels)\n",
    "\n",
    "                # The call to `model` always returns a tuple, so we need to pull the \n",
    "                # loss value out of the tuple.\n",
    "                loss = outputs[0]\n",
    "                # if(params['logging']=='neptune'):\n",
    "                # \tneptune.log_metric('batch_loss',loss)\n",
    "                # Accumulate the training loss over all of the batches so that we can\n",
    "                # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "                # single value; the `.item()` function just returns the Python value \n",
    "                # from the tensor.\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Perform a backward pass to calculate the gradients.\n",
    "                loss.backward()\n",
    "\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                # This is to help prevent the \"exploding gradients\" problem.\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                # Update parameters and take a step using the computed gradient.\n",
    "                # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "                # modified based on their gradients, the learning rate, etc.\n",
    "                optimizer.step()\n",
    "                # Update the learning rate.\n",
    "                scheduler.step()\n",
    "\n",
    "            # Calculate the average loss over the training data.\n",
    "            avg_train_loss = total_loss / len(train_dataloader)\n",
    "            train_fscore,train_accuracy=Eval_phase(params,train_dataloader,'train',model)\n",
    "            print('avg_train_loss',avg_train_loss)\n",
    "            print('train_fscore',train_fscore)\n",
    "            print('train_accuracy',train_accuracy)\n",
    "            # Store the loss value for plotting the learning curve.\n",
    "            loss_values.append(avg_train_loss)\n",
    "            val_fscore,val_accuracy=Eval_phase(params,validation_dataloader,'val',model)\t\t\n",
    "            #Report the final accuracy for this validation run.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=\"I go here\"\n",
    "\n",
    "front_sent=sent[0:2]\n",
    "back_sent=sent[-2:]\n",
    "print(front_sent)\n",
    "print(back_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_bert(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data=pd.read_csv('Total_data_annotated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'max_length':128,\n",
    "    'path_files': 'models_saved/mbert_fearspeech/',\n",
    "    'what_bert':'normal',\n",
    "    'batch_size':32,\n",
    "    'is_train':True,\n",
    "    'learning_rate':2e-5,\n",
    "    'epsilon':1e-8,\n",
    "    'random_seed':2020,\n",
    "    'weights':[1.0,9.0],\n",
    "    'epochs':5\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERT_for_inference(params):\n",
    "    model=select_model(params['what_bert'],params['path_files'],params['weights'])\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    total_data=pd.read_csv('../../Data/new_data_lang_without_spam_translated.csv',nrows=1000)\n",
    "    all_sentences = total_data.text\n",
    "    all_labels=total_data.label\n",
    "    input_total_ids,att_masks_total=combine_features(all_sentences,tokenizer,params['max_length'],\n",
    "                                                     take_pair=False,take_target=False)\n",
    "    train_dataloader = return_dataloader(input_total_ids,all_labels,att_masks_total,batch_size=params['batch_size'],is_train=params['is_train'])\n",
    "    \n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        logits = outputs[0]\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Accumulate the total accuracy.\n",
    "        pred_labels+=list(np.argmax(logits, axis=1).flatten())\n",
    "        \n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\" Accuracy: {0:.2f}\".format(testacc))\n",
    "    print(\" Fscore: {0:.2f}\".format(testf1))\n",
    "    print(\" Test took: {:}\".format(format_time(time.time() - t0)))\n",
    "    return testf1,testacc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0427 08:11:31.913552 139727928391488 configuration_utils.py:231] loading configuration file models_saved/mbert_fearspeech/config.json\n",
      "I0427 08:11:31.915510 139727928391488 configuration_utils.py:256] Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "I0427 08:11:31.917342 139727928391488 modeling_utils.py:438] loading weights file models_saved/mbert_fearspeech/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "BERT_for_inference(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-punyajoy_gpu] *",
   "language": "python",
   "name": "conda-env-.conda-punyajoy_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytextrank\n",
      "  Downloading pytextrank-2.0.1-py3-none-any.whl (10 kB)\n",
      "Collecting scattertext\n",
      "  Downloading scattertext-0.0.2.64-py3-none-any.whl (6.9 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.9 MB 764 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting spacy\n",
      "  Using cached spacy-2.2.4-cp37-cp37m-manylinux1_x86_64.whl (10.6 MB)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.14-py2.py3-none-any.whl (18 kB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.6 MB 49.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting coverage\n",
      "  Downloading coverage-5.1-cp37-cp37m-manylinux1_x86_64.whl (227 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 227 kB 16.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting statsmodels\n",
      "  Downloading statsmodels-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (8.7 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.7 MB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from scattertext) (0.22.1)\n",
      "Requirement already satisfied: six in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from scattertext) (1.14.0)\n",
      "Requirement already satisfied: scipy in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from scattertext) (1.4.1)\n",
      "Requirement already satisfied: pandas in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from scattertext) (1.0.1)\n",
      "Collecting mock\n",
      "  Downloading mock-4.0.2-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: numpy in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from scattertext) (1.18.1)\n",
      "Collecting thinc==7.4.0\n",
      "  Using cached thinc-7.4.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Collecting srsly<1.1.0,>=1.0.2\n",
      "  Using cached srsly-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (185 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (19 kB)\n",
      "Requirement already satisfied: setuptools in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy->pytextrank) (45.1.0.post20200127)\n",
      "Collecting blis<0.5.0,>=0.4.0\n",
      "  Using cached blis-0.4.1-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Using cached catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting wasabi<1.1.0,>=0.4.0\n",
      "  Using cached wasabi-0.6.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy->pytextrank) (2.22.0)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.2-cp37-cp37m-manylinux1_x86_64.whl (118 kB)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy->pytextrank) (4.43.0)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.3-cp37-cp37m-manylinux1_x86_64.whl (32 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from networkx->pytextrank) (4.4.1)\n",
      "Collecting patsy>=0.5\n",
      "  Using cached patsy-0.5.1-py2.py3-none-any.whl (231 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/punyajoy/.local/lib/python3.7/site-packages (from scikit-learn->scattertext) (0.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from pandas->scattertext) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from pandas->scattertext) (2019.3)\n",
      "Collecting importlib-metadata>=0.20; python_version < \"3.8\"\n",
      "  Using cached importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (1.25.8)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "\u001b[31mERROR: inltk 0.8.1 requires beautifulsoup4, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: inltk 0.8.1 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: inltk 0.8.1 requires packaging, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: inltk 0.8.1 requires Pillow, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: inltk 0.8.1 requires pyyaml, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires beautifulsoup4, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires packaging, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires Pillow, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires pyyaml, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires torch>=1.0.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires torchvision, which is not installed.\u001b[0m\n",
      "Installing collected packages: srsly, murmurhash, cymem, preshed, blis, zipp, importlib-metadata, catalogue, wasabi, plac, thinc, spacy, graphviz, networkx, coverage, pytextrank, patsy, statsmodels, mock, scattertext\n",
      "Successfully installed blis-0.4.1 catalogue-1.0.0 coverage-5.1 cymem-2.0.3 graphviz-0.14 importlib-metadata-1.6.0 mock-4.0.2 murmurhash-1.0.2 networkx-2.4 patsy-0.5.1 plac-1.1.3 preshed-3.0.2 pytextrank-2.0.1 scattertext-0.0.2.64 spacy-2.2.4 srsly-1.0.2 statsmodels-0.11.1 thinc-7.4.0 wasabi-0.6.0 zipp-3.1.0\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-abf377698ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytextrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscattertext\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aiethics/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aiethics/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "!pip install pytextrank scattertext\n",
    "\n",
    "import spacy\n",
    "from scattertext import SampleCorpora, PhraseMachinePhrases, dense_rank, RankDifference, AssociationCompactor, produce_scattertext_explorer\n",
    "from scattertext.CorpusFromPandas import CorpusFromPandas\n",
    "import pytextrank, spacy\n",
    "import scattertext as st\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../../Data/new_data_lang_without_spam_translated_BERT_pred.csv\")\n",
    "#del(dataFrame[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.dropna(subset=['translated', 'preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>group_id_anonymized</th>\n",
       "      <th>lang</th>\n",
       "      <th>message_text</th>\n",
       "      <th>phone_num_anonymized</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>translated</th>\n",
       "      <th>preds</th>\n",
       "      <th>pred_probab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>577</td>\n",
       "      <td>hi</td>\n",
       "      <td>*‡§≤‡§ò‡•Å ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à*  ‡§®‡§ø‡§É‡§∂‡•Å‡§≤‡•ç‡§ï ‡§¨‡•ã‡§∞‡§ø‡§Ç‡§ó ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§π‡•á‡§§‡•Å 55 ‡§ï‡§∞...</td>\n",
       "      <td>178320</td>\n",
       "      <td>1549559608000</td>\n",
       "      <td>* Provision of Rs. 55 crore for minor irrigati...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2037</td>\n",
       "      <td>hi</td>\n",
       "      <td>*üì∞FR62* *üëâ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä-‡§è‡§®‡§∏‡•Ä‡§Ü‡§∞ ‡§Æ‡•á‡§Ç ‡§∂‡§ø‡§Æ‡§≤‡§æ ‡§ú‡•à‡§∏‡•Ä ‡§¨‡§∞‡•ç‡§´‡§¨‡§æ‡§∞...</td>\n",
       "      <td>39877</td>\n",
       "      <td>1549559738000</td>\n",
       "      <td>* üì∞  üì∞FR62 üëâ  * * Shimla-like snowfall in Delh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3634</td>\n",
       "      <td>hi</td>\n",
       "      <td>‡§ï‡§≤ ‡§Æ‡•à‡§®‡•á ‡§è‡§ï ‡§Ü‡§¶‡§Æ‡•Ä ‡§∏‡•á ‡§≤‡§ø‡§´‡•ç‡§ü ‡§Æ‡§æ‡§Å‡§ó‡§æ ‡§â‡§∏‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ...</td>\n",
       "      <td>198635</td>\n",
       "      <td>1549559843000</td>\n",
       "      <td>Yesterday I asked for a lift from a man, after...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2284</td>\n",
       "      <td>hi</td>\n",
       "      <td>‡§ï‡§≤ ‡§Æ‡•à‡§®‡•á ‡§è‡§ï ‡§Ü‡§¶‡§Æ‡•Ä ‡§∏‡•á ‡§≤‡§ø‡§´‡•ç‡§ü ‡§Æ‡§æ‡§Å‡§ó‡§æ ‡§â‡§∏‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ...</td>\n",
       "      <td>198635</td>\n",
       "      <td>1549559851000</td>\n",
       "      <td>Yesterday I asked for a lift from a man, after...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3700</td>\n",
       "      <td>te</td>\n",
       "      <td>‡∞∏‡∞∞‡±ç‡∞µ‡±á‡∞≤‡±Å ‡∞∏‡±Ç‡∞∏‡∞ø ‡∞Æ‡±Å‡∞∞‡∞ø‡∞∏‡∞ø ‡∞™‡±ã‡∞µ‡∞¶‡±ç‡∞¶‡±Å ‡∞Æ‡∞ø‡∞§‡±ç‡∞∞‡±Å‡∞≤‡±Å ‡∞¨‡∞æ‡∞¨‡±Å ‡∞ú‡∞ø‡∞§‡±ç...</td>\n",
       "      <td>153553</td>\n",
       "      <td>1549559896000</td>\n",
       "      <td>Surveys Don't Surprise Friends</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0           0             0               0               4.0   \n",
       "1           1             1               1               9.0   \n",
       "2           2             2               2              10.0   \n",
       "3           3             3               3              11.0   \n",
       "4           4             4               4              13.0   \n",
       "\n",
       "   Unnamed: 0.1.1.1.1  group_id_anonymized lang  \\\n",
       "0                 4.0                  577   hi   \n",
       "1                 9.0                 2037   hi   \n",
       "2                10.0                 3634   hi   \n",
       "3                11.0                 2284   hi   \n",
       "4                13.0                 3700   te   \n",
       "\n",
       "                                        message_text  phone_num_anonymized  \\\n",
       "0  *‡§≤‡§ò‡•Å ‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à*  ‡§®‡§ø‡§É‡§∂‡•Å‡§≤‡•ç‡§ï ‡§¨‡•ã‡§∞‡§ø‡§Ç‡§ó ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§π‡•á‡§§‡•Å 55 ‡§ï‡§∞...                178320   \n",
       "1  *üì∞FR62* *üëâ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä-‡§è‡§®‡§∏‡•Ä‡§Ü‡§∞ ‡§Æ‡•á‡§Ç ‡§∂‡§ø‡§Æ‡§≤‡§æ ‡§ú‡•à‡§∏‡•Ä ‡§¨‡§∞‡•ç‡§´‡§¨‡§æ‡§∞...                 39877   \n",
       "2  ‡§ï‡§≤ ‡§Æ‡•à‡§®‡•á ‡§è‡§ï ‡§Ü‡§¶‡§Æ‡•Ä ‡§∏‡•á ‡§≤‡§ø‡§´‡•ç‡§ü ‡§Æ‡§æ‡§Å‡§ó‡§æ ‡§â‡§∏‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ...                198635   \n",
       "3  ‡§ï‡§≤ ‡§Æ‡•à‡§®‡•á ‡§è‡§ï ‡§Ü‡§¶‡§Æ‡•Ä ‡§∏‡•á ‡§≤‡§ø‡§´‡•ç‡§ü ‡§Æ‡§æ‡§Å‡§ó‡§æ ‡§â‡§∏‡§ï‡•á ‡§¨‡§æ‡§¶ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ...                198635   \n",
       "4  ‡∞∏‡∞∞‡±ç‡∞µ‡±á‡∞≤‡±Å ‡∞∏‡±Ç‡∞∏‡∞ø ‡∞Æ‡±Å‡∞∞‡∞ø‡∞∏‡∞ø ‡∞™‡±ã‡∞µ‡∞¶‡±ç‡∞¶‡±Å ‡∞Æ‡∞ø‡∞§‡±ç‡∞∞‡±Å‡∞≤‡±Å ‡∞¨‡∞æ‡∞¨‡±Å ‡∞ú‡∞ø‡∞§‡±ç...                153553   \n",
       "\n",
       "       timestamp                                         translated  preds  \\\n",
       "0  1549559608000  * Provision of Rs. 55 crore for minor irrigati...      0   \n",
       "1  1549559738000  * üì∞  üì∞FR62 üëâ  * * Shimla-like snowfall in Delh...      0   \n",
       "2  1549559843000  Yesterday I asked for a lift from a man, after...      0   \n",
       "3  1549559851000  Yesterday I asked for a lift from a man, after...      0   \n",
       "4  1549559896000                   Surveys Don't Surprise Friends        0   \n",
       "\n",
       "   pred_probab  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(df['translated'])\n",
    "actual_label =list(df['pred_probab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* Provision of Rs. 55 crore for minor irrigation * Free boring scheme. A provision of Rs 70 crore proposed under the medium deep tubewell scheme. A provision of 20 crore rupees for construction and restoration of community blast wells in the plateau areas of the state.  '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = {'`','~','!','@','#','$','%','^','&','*','(',')','_','-','+','=','{','[','}','}','|',':',';','\"','<','>','.','?'}\n",
    "\n",
    "import re\n",
    "#import nltk\n",
    "#from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "#nltk.download('stopwords')\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "texts=[]\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    #print(i)\n",
    "    #text = re.sub('[^a-zA-Z]', ' ', data[i])\n",
    "    text = re.sub(r\"http\\S+\", \"\", data[i])\n",
    "    #text= deEmojify(text)\n",
    "    text = text.lower()\n",
    "    text = ''.join([i for i in text if not i.isdigit() and i not in symbols])\n",
    "    #text = text.split()\n",
    "    #text = word_tokenize(text)\n",
    "    #lemmatizer = WordNetLemmatizer()\n",
    "    #text = [lemmatizer.lemmatize(word) for word in text if not word in set(stopwords.words('english'))]\n",
    "    #text = ''.join([i for i in text if not i.isdigit()])\n",
    "    #text =[word for word in text if len(word)> 1]\n",
    "    #text = ' '.join(text)\n",
    "    texts.append(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[]\n",
    "cnt=0\n",
    "for i in range(0, len(actual_label)):\n",
    "    if (actual_label[i] > 0.8):\n",
    "        label.append(1)\n",
    "        cnt+=1\n",
    "    else:\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21323\n"
     ]
    }
   ],
   "source": [
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558551\n",
      "1558551\n"
     ]
    }
   ],
   "source": [
    "print(len(label))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.DataFrame(list(zip(texts, label)), \n",
    "               columns =['text', 'label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>provision of rs  crore for minor irrigation  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üì∞  üì∞fr üëâ    shimlalike snowfall in delhincr, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yesterday i asked for a lift from a man, after...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yesterday i asked for a lift from a man, after...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surveys don't surprise friends</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0   provision of rs  crore for minor irrigation  ...      0\n",
       "1   üì∞  üì∞fr üëâ    shimlalike snowfall in delhincr, ...      0\n",
       "2  yesterday i asked for a lift from a man, after...      0\n",
       "3  yesterday i asked for a lift from a man, after...      0\n",
       "4                   surveys don't surprise friends        0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: setuptools in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (45.1.0.post20200127)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.43.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: thinc==7.4.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m‚úî Linking successful\u001b[0m\n",
      "/home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages/en_core_web_sm\n",
      "-->\n",
      "/home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_df = dataFrame.assign(\n",
    "    parse=lambda df: df.text.apply(nlp),\n",
    "    party=lambda df: df.label.apply({1.0: 'FearSpeech', 0.0: 'NormalSpeech'}.get)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(\n",
    "    convention_df,\n",
    "    category_col='party',\n",
    "    parsed_col='parse',\n",
    "    feats_from_spacy_doc=st.PyTextRankPhrases()\n",
    ").build(\n",
    ").compact(\n",
    "    AssociationCompactor(2000, use_non_text_features=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_category_scores = corpus.get_metadata_freq_df('')\n",
    "print(term_category_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_ranks = np.argsort(np.argsort(-term_category_scores, axis=0), axis=0) + 1\n",
    "metadata_descriptions = {\n",
    "    term: '<br/>' + '<br/>'.join(\n",
    "        '<b>%s</b> TextRank score rank: %s/%s' % (cat, term_ranks.loc[term, cat], corpus.get_num_metadata())\n",
    "        for cat in corpus.get_categories())\n",
    "    for term in corpus.get_metadata()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_specific_prominence = term_category_scores.apply(\n",
    "    lambda r: r.FearSpeech if r.FearSpeech > r.NormalSpeech else -r.NormalSpeech,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html1 = produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category='FearSpeech',\n",
    "    minimum_term_frequency=10,\n",
    "    pmi_threshold_coefficient=0,\n",
    "    width_in_pixels=1000,\n",
    "    transform=dense_rank,\n",
    "    #metadata=corpus.get_df()['speaker'],\n",
    "    scores=category_specific_prominence,\n",
    "    sort_by_dist=False,\n",
    "    use_non_text_features=True,\n",
    "    topic_model_term_lists={term: [term] for term in         \n",
    "                            corpus.get_metadata()},\n",
    "    topic_model_preview_size=0,\n",
    "    metadata_descriptions=metadata_descriptions,\n",
    "    use_full_doc=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"uConvention-Visualization2.html\", 'wb').write(html1.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-aiethics]",
   "language": "python",
   "name": "conda-env-.conda-aiethics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

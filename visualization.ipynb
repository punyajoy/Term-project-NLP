{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytextrank\n",
      "  Downloading pytextrank-2.0.1-py3-none-any.whl (10 kB)\n",
      "Collecting scattertext\n",
      "  Downloading scattertext-0.0.2.64-py3-none-any.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 764 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting spacy\n",
      "  Using cached spacy-2.2.4-cp37-cp37m-manylinux1_x86_64.whl (10.6 MB)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.14-py2.py3-none-any.whl (18 kB)\n",
      "Collecting networkx\n",
      "  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 49.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting coverage\n",
      "  Downloading coverage-5.1-cp37-cp37m-manylinux1_x86_64.whl (227 kB)\n",
      "\u001b[K     |████████████████████████████████| 227 kB 16.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting statsmodels\n",
      "  Downloading statsmodels-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (8.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.7 MB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from scattertext) (0.22.1)\n",
      "Requirement already satisfied: six in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from scattertext) (1.14.0)\n",
      "Requirement already satisfied: scipy in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from scattertext) (1.4.1)\n",
      "Requirement already satisfied: pandas in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from scattertext) (1.0.1)\n",
      "Collecting mock\n",
      "  Downloading mock-4.0.2-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: numpy in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from scattertext) (1.18.1)\n",
      "Collecting thinc==7.4.0\n",
      "  Using cached thinc-7.4.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Collecting srsly<1.1.0,>=1.0.2\n",
      "  Using cached srsly-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (185 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (19 kB)\n",
      "Requirement already satisfied: setuptools in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy->pytextrank) (45.1.0.post20200127)\n",
      "Collecting blis<0.5.0,>=0.4.0\n",
      "  Using cached blis-0.4.1-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\n",
      "Collecting catalogue<1.1.0,>=0.0.7\n",
      "  Using cached catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\n",
      "Collecting wasabi<1.1.0,>=0.4.0\n",
      "  Using cached wasabi-0.6.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy->pytextrank) (2.22.0)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.2-cp37-cp37m-manylinux1_x86_64.whl (118 kB)\n",
      "Collecting plac<1.2.0,>=0.9.6\n",
      "  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy->pytextrank) (4.43.0)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.3-cp37-cp37m-manylinux1_x86_64.whl (32 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from networkx->pytextrank) (4.4.1)\n",
      "Collecting patsy>=0.5\n",
      "  Using cached patsy-0.5.1-py2.py3-none-any.whl (231 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/punyajoy/.local/lib/python3.7/site-packages (from scikit-learn->scattertext) (0.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from pandas->scattertext) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from pandas->scattertext) (2019.3)\n",
      "Collecting importlib-metadata>=0.20; python_version < \"3.8\"\n",
      "  Using cached importlib_metadata-1.6.0-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (1.25.8)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "\u001b[31mERROR: inltk 0.8.1 requires beautifulsoup4, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: inltk 0.8.1 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: inltk 0.8.1 requires packaging, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: inltk 0.8.1 requires Pillow, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: inltk 0.8.1 requires pyyaml, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires beautifulsoup4, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires packaging, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires Pillow, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires pyyaml, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires torch>=1.0.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.57 requires torchvision, which is not installed.\u001b[0m\n",
      "Installing collected packages: srsly, murmurhash, cymem, preshed, blis, zipp, importlib-metadata, catalogue, wasabi, plac, thinc, spacy, graphviz, networkx, coverage, pytextrank, patsy, statsmodels, mock, scattertext\n",
      "Successfully installed blis-0.4.1 catalogue-1.0.0 coverage-5.1 cymem-2.0.3 graphviz-0.14 importlib-metadata-1.6.0 mock-4.0.2 murmurhash-1.0.2 networkx-2.4 patsy-0.5.1 plac-1.1.3 preshed-3.0.2 pytextrank-2.0.1 scattertext-0.0.2.64 spacy-2.2.4 srsly-1.0.2 statsmodels-0.11.1 thinc-7.4.0 wasabi-0.6.0 zipp-3.1.0\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-abf377698ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytextrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscattertext\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aiethics/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aiethics/lib/python3.7/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "!pip install pytextrank scattertext\n",
    "\n",
    "import spacy\n",
    "from scattertext import SampleCorpora, PhraseMachinePhrases, dense_rank, RankDifference, AssociationCompactor, produce_scattertext_explorer\n",
    "from scattertext.CorpusFromPandas import CorpusFromPandas\n",
    "import pytextrank, spacy\n",
    "import scattertext as st\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../../Data/new_data_lang_without_spam_translated_BERT_pred.csv\")\n",
    "#del(dataFrame[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.dropna(subset=['translated', 'preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1</th>\n",
       "      <th>Unnamed: 0.1.1.1.1</th>\n",
       "      <th>group_id_anonymized</th>\n",
       "      <th>lang</th>\n",
       "      <th>message_text</th>\n",
       "      <th>phone_num_anonymized</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>translated</th>\n",
       "      <th>preds</th>\n",
       "      <th>pred_probab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>577</td>\n",
       "      <td>hi</td>\n",
       "      <td>*लघु सिंचाई*  निःशुल्क बोरिंग योजना हेतु 55 कर...</td>\n",
       "      <td>178320</td>\n",
       "      <td>1549559608000</td>\n",
       "      <td>* Provision of Rs. 55 crore for minor irrigati...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2037</td>\n",
       "      <td>hi</td>\n",
       "      <td>*📰FR62* *👉दिल्ली-एनसीआर में शिमला जैसी बर्फबार...</td>\n",
       "      <td>39877</td>\n",
       "      <td>1549559738000</td>\n",
       "      <td>* 📰  📰FR62 👉  * * Shimla-like snowfall in Delh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3634</td>\n",
       "      <td>hi</td>\n",
       "      <td>कल मैने एक आदमी से लिफ्ट माँगा उसके बाद धन्यवा...</td>\n",
       "      <td>198635</td>\n",
       "      <td>1549559843000</td>\n",
       "      <td>Yesterday I asked for a lift from a man, after...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2284</td>\n",
       "      <td>hi</td>\n",
       "      <td>कल मैने एक आदमी से लिफ्ट माँगा उसके बाद धन्यवा...</td>\n",
       "      <td>198635</td>\n",
       "      <td>1549559851000</td>\n",
       "      <td>Yesterday I asked for a lift from a man, after...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3700</td>\n",
       "      <td>te</td>\n",
       "      <td>సర్వేలు సూసి మురిసి పోవద్దు మిత్రులు బాబు జిత్...</td>\n",
       "      <td>153553</td>\n",
       "      <td>1549559896000</td>\n",
       "      <td>Surveys Don't Surprise Friends</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  Unnamed: 0.1.1.1  \\\n",
       "0           0             0               0               4.0   \n",
       "1           1             1               1               9.0   \n",
       "2           2             2               2              10.0   \n",
       "3           3             3               3              11.0   \n",
       "4           4             4               4              13.0   \n",
       "\n",
       "   Unnamed: 0.1.1.1.1  group_id_anonymized lang  \\\n",
       "0                 4.0                  577   hi   \n",
       "1                 9.0                 2037   hi   \n",
       "2                10.0                 3634   hi   \n",
       "3                11.0                 2284   hi   \n",
       "4                13.0                 3700   te   \n",
       "\n",
       "                                        message_text  phone_num_anonymized  \\\n",
       "0  *लघु सिंचाई*  निःशुल्क बोरिंग योजना हेतु 55 कर...                178320   \n",
       "1  *📰FR62* *👉दिल्ली-एनसीआर में शिमला जैसी बर्फबार...                 39877   \n",
       "2  कल मैने एक आदमी से लिफ्ट माँगा उसके बाद धन्यवा...                198635   \n",
       "3  कल मैने एक आदमी से लिफ्ट माँगा उसके बाद धन्यवा...                198635   \n",
       "4  సర్వేలు సూసి మురిసి పోవద్దు మిత్రులు బాబు జిత్...                153553   \n",
       "\n",
       "       timestamp                                         translated  preds  \\\n",
       "0  1549559608000  * Provision of Rs. 55 crore for minor irrigati...      0   \n",
       "1  1549559738000  * 📰  📰FR62 👉  * * Shimla-like snowfall in Delh...      0   \n",
       "2  1549559843000  Yesterday I asked for a lift from a man, after...      0   \n",
       "3  1549559851000  Yesterday I asked for a lift from a man, after...      0   \n",
       "4  1549559896000                   Surveys Don't Surprise Friends        0   \n",
       "\n",
       "   pred_probab  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(df['translated'])\n",
    "actual_label =list(df['pred_probab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* Provision of Rs. 55 crore for minor irrigation * Free boring scheme. A provision of Rs 70 crore proposed under the medium deep tubewell scheme. A provision of 20 crore rupees for construction and restoration of community blast wells in the plateau areas of the state.  '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = {'`','~','!','@','#','$','%','^','&','*','(',')','_','-','+','=','{','[','}','}','|',':',';','\"','<','>','.','?'}\n",
    "\n",
    "import re\n",
    "#import nltk\n",
    "#from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "#nltk.download('stopwords')\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "texts=[]\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    #print(i)\n",
    "    #text = re.sub('[^a-zA-Z]', ' ', data[i])\n",
    "    text = re.sub(r\"http\\S+\", \"\", data[i])\n",
    "    #text= deEmojify(text)\n",
    "    text = text.lower()\n",
    "    text = ''.join([i for i in text if not i.isdigit() and i not in symbols])\n",
    "    #text = text.split()\n",
    "    #text = word_tokenize(text)\n",
    "    #lemmatizer = WordNetLemmatizer()\n",
    "    #text = [lemmatizer.lemmatize(word) for word in text if not word in set(stopwords.words('english'))]\n",
    "    #text = ''.join([i for i in text if not i.isdigit()])\n",
    "    #text =[word for word in text if len(word)> 1]\n",
    "    #text = ' '.join(text)\n",
    "    texts.append(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[]\n",
    "cnt=0\n",
    "for i in range(0, len(actual_label)):\n",
    "    if (actual_label[i] > 0.8):\n",
    "        label.append(1)\n",
    "        cnt+=1\n",
    "    else:\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21323\n"
     ]
    }
   ],
   "source": [
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1558551\n",
      "1558551\n"
     ]
    }
   ],
   "source": [
    "print(len(label))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = pd.DataFrame(list(zip(texts, label)), \n",
    "               columns =['text', 'label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>provision of rs  crore for minor irrigation  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>📰  📰fr 👉    shimlalike snowfall in delhincr, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yesterday i asked for a lift from a man, after...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yesterday i asked for a lift from a man, after...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surveys don't surprise friends</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0   provision of rs  crore for minor irrigation  ...      0\n",
       "1   📰  📰fr 👉    shimlalike snowfall in delhincr, ...      0\n",
       "2  yesterday i asked for a lift from a man, after...      0\n",
       "3  yesterday i asked for a lift from a man, after...      0\n",
       "4                   surveys don't surprise friends        0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: setuptools in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (45.1.0.post20200127)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.43.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: thinc==7.4.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.11.28)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages/en_core_web_sm\n",
      "-->\n",
      "/home/punyajoy/.conda/envs/aiethics/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_df = dataFrame.assign(\n",
    "    parse=lambda df: df.text.apply(nlp),\n",
    "    party=lambda df: df.label.apply({1.0: 'FearSpeech', 0.0: 'NormalSpeech'}.get)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(\n",
    "    convention_df,\n",
    "    category_col='party',\n",
    "    parsed_col='parse',\n",
    "    feats_from_spacy_doc=st.PyTextRankPhrases()\n",
    ").build(\n",
    ").compact(\n",
    "    AssociationCompactor(2000, use_non_text_features=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_category_scores = corpus.get_metadata_freq_df('')\n",
    "print(term_category_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_ranks = np.argsort(np.argsort(-term_category_scores, axis=0), axis=0) + 1\n",
    "metadata_descriptions = {\n",
    "    term: '<br/>' + '<br/>'.join(\n",
    "        '<b>%s</b> TextRank score rank: %s/%s' % (cat, term_ranks.loc[term, cat], corpus.get_num_metadata())\n",
    "        for cat in corpus.get_categories())\n",
    "    for term in corpus.get_metadata()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_specific_prominence = term_category_scores.apply(\n",
    "    lambda r: r.FearSpeech if r.FearSpeech > r.NormalSpeech else -r.NormalSpeech,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html1 = produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category='FearSpeech',\n",
    "    minimum_term_frequency=10,\n",
    "    pmi_threshold_coefficient=0,\n",
    "    width_in_pixels=1000,\n",
    "    transform=dense_rank,\n",
    "    #metadata=corpus.get_df()['speaker'],\n",
    "    scores=category_specific_prominence,\n",
    "    sort_by_dist=False,\n",
    "    use_non_text_features=True,\n",
    "    topic_model_term_lists={term: [term] for term in         \n",
    "                            corpus.get_metadata()},\n",
    "    topic_model_preview_size=0,\n",
    "    metadata_descriptions=metadata_descriptions,\n",
    "    use_full_doc=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open(\"uConvention-Visualization2.html\", 'wb').write(html1.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-aiethics]",
   "language": "python",
   "name": "conda-env-.conda-aiethics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
